# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Rr5187j9XNivvOomizUr1UyNF-Hyan6
"""




# HR Chatbot Web App using Streamlit + LangChain + Static Files from GitHub

import streamlit as st
import os
from langchain_community.document_loaders import PyPDFLoader, UnstructuredExcelLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_huggingface import HuggingFaceEndpoint
import os
llm = HuggingFaceEndpoint(repo_id="...", huggingfacehub_api_token=os.getenv("HUGGINGFACEHUB_API_TOKEN")) 


# ---------------- Setup ---------------- #
st.set_page_config(page_title="CISF Chatbot", layout="wide")
st.title("ðŸ¤– CISF Chatbot - Ask Your Query")

# ---------------- Load Files from data/ folder ---------------- #
data_dir = "data"
os.makedirs(data_dir, exist_ok=True)

documents = []
for filename in os.listdir(data_dir):
    path = os.path.join(data_dir, filename)
    if filename.endswith(".pdf"):
        loader = PyPDFLoader(path)
    elif filename.endswith(".xlsx"):
        loader = UnstructuredExcelLoader(path)
    else:
        continue
    documents.extend(loader.load())

# ---------------- Build Vector Store ---------------- #
if documents:
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_documents(documents)

    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    db = FAISS.from_documents(chunks, embeddings)
    retriever = db.as_retriever()

    llm = HuggingFaceHub(
        repo_id="google/flan-t5-base",
        model_kwargs={"temperature": 0.3, "max_length": 512}
    )

    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

    st.subheader("ðŸ’¬ Ask a question")
    query = st.text_input("Type your question here...")

    if query:
        with st.spinner("ðŸ¤” Thinking..."):
            response = qa_chain.run(query)
        st.success(response)
else:
    st.warning("No documents found. Please add files to the 'data/' folder in your GitHub repo.")
